{
nkita
nkita
nkita
 "cells": [
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 1,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [
nkita
nkita
nkita
    {
nkita
nkita
nkita
     "name": "stderr",
nkita
nkita
nkita
     "output_type": "stream",
nkita
nkita
nkita
     "text": [
nkita
nkita
nkita
      "2023-11-07 23:08:28.411832: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
nkita
nkita
nkita
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
nkita
nkita
nkita
      "2023-11-07 23:08:28.579046: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
nkita
nkita
nkita
      "2023-11-07 23:08:30.119332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
nkita
nkita
nkita
      "2023-11-07 23:08:30.119526: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
nkita
nkita
nkita
      "2023-11-07 23:08:30.119549: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
nkita
nkita
nkita
     ]
nkita
nkita
nkita
    }
nkita
nkita
nkita
   ],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "import json\n",
nkita
nkita
nkita
    "import pandas as pd\n",
nkita
nkita
nkita
    "import warnings\n",
nkita
nkita
nkita
    "import tqdm\n",
nkita
nkita
nkita
    "import os\n",
nkita
nkita
nkita
    "import string\n",
nkita
nkita
nkita
    "import re\n",
nkita
nkita
nkita
    "import csv\n",
nkita
nkita
nkita
    "warnings.filterwarnings('ignore')\n",
nkita
nkita
nkita
    "from rouge import Rouge\n",
nkita
nkita
nkita
    "rouge = Rouge()\n",
nkita
nkita
nkita
    "import evaluate"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 2,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "bertscore = evaluate.load('bertscore')\n",
nkita
nkita
nkita
    "em = evaluate.load('exact_match')"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 3,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "preds = []\n",
nkita
nkita
nkita
    "refs = []"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 4,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "from collections import defaultdict"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 5,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 6,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "langScoreRefs = {'hi':[],'en':[],'bn':[],'ta':[],'or':[],'pa':[]}\n",
nkita
nkita
nkita
    "langScorePreds = {'hi':[],'en':[],'bn':[],'ta':[],'or':[],'pa':[]}\n",
nkita
nkita
nkita
    "langScore = {'hi':[],'en':[],'bn':[],'ta':[],'or':[],'pa':[]}\n",
nkita
nkita
nkita
    "fin = open('final_article.csv', mode ='r')\n",
nkita
nkita
nkita
    "csvData = csv.reader(fin)\n",
nkita
nkita
nkita
    "for i,lineData in enumerate(csvData):\n",
nkita
nkita
nkita
    "    if i == 0:\n",
nkita
nkita
nkita
    "        continue\n",
nkita
nkita
nkita
    "    lang = lineData[1][:2]\n",
nkita
nkita
nkita
    "    x = lineData[3].split(' ')\n",
nkita
nkita
nkita
    "    y = lineData[2].split(' ')\n",
nkita
nkita
nkita
    "    \n",
nkita
nkita
nkita
    "    x = [i for i in x if i!= '']\n",
nkita
nkita
nkita
    "    y = [i for i in y if i!= '']\n",
nkita
nkita
nkita
    "    \n",
nkita
nkita
nkita
    "    if len(x) > len(y):\n",
nkita
nkita
nkita
    "        y = y + ['<pad>']*(len(x) - len(y))\n",
nkita
nkita
nkita
    "    elif len(y) > len(x):\n",
nkita
nkita
nkita
    "        x = x + ['<pad>']*(len(y) - len(x))\n",
nkita
nkita
nkita
    "        \n",
nkita
nkita
nkita
    "#     results = em.compute(predictions=x, references=y)\n",
nkita
nkita
nkita
    "#     langScore[lang].append(round(results['exact_match'], 2))\n",
nkita
nkita
nkita
    "#     results = bertscore.compute(predictions=[lineData[3]], references=[lineData[2]], model_type=\"bert-base-multilingual-cased\")\n",
nkita
nkita
nkita
    "#     langScore[lang].append(results['f1'][0])\n",
nkita
nkita
nkita
    "    \n",
nkita
nkita
nkita
    "    langScorePreds[lang].extend(x)\n",
nkita
nkita
nkita
    "    langScoreRefs[lang].extend(y)\n",
nkita
nkita
nkita
    "fin.close()"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 8,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "for key in langScore.keys():\n",
nkita
nkita
nkita
    "    if len(langScore[key]) != 0:\n",
nkita
nkita
nkita
    "        print(f\"For language: {key}, average Exact Match score is: {sum(langScore[key])/len(langScore[key])}\")"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 9,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [
nkita
nkita
nkita
    {
nkita
nkita
nkita
     "name": "stdout",
nkita
nkita
nkita
     "output_type": "stream",
nkita
nkita
nkita
     "text": [
nkita
nkita
nkita
      "hi {'acc': 0.630667578035999, 'p': 0.6576921870681213, 'r': 0.630667578035999, 'f1': 0.640187223670143}\n",
nkita
nkita
nkita
      "en {'acc': 0.46185286103542234, 'p': 0.5250970933780474, 'r': 0.46185286103542234, 'f1': 0.4759085933734836}\n",
nkita
nkita
nkita
      "bn {'acc': 0.5898498187467633, 'p': 0.5013551158220036, 'r': 0.5898498187467633, 'f1': 0.5278847985683925}\n",
nkita
nkita
nkita
      "ta {'acc': 0.6036179835062516, 'p': 0.7498223206932829, 'r': 0.6036179835062516, 'f1': 0.65691687773671}\n",
nkita
nkita
nkita
      "or {'acc': 0.43284671532846714, 'p': 0.6185370812282622, 'r': 0.43284671532846714, 'f1': 0.49426936096750496}\n",
nkita
nkita
nkita
      "pa {'acc': 0.3891242937853107, 'p': 0.4442298121478621, 'r': 0.3891242937853107, 'f1': 0.40775863227103276}\n"
nkita
nkita
nkita
     ]
nkita
nkita
nkita
    }
nkita
nkita
nkita
   ],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "scores = defaultdict(float)\n",
nkita
nkita
nkita
    "for ln in langScoreRefs.keys():\n",
nkita
nkita
nkita
    "    y_true = langScoreRefs[ln]\n",
nkita
nkita
nkita
    "    y_pred = langScorePreds[ln]\n",
nkita
nkita
nkita
    "    metric_dict = {'acc': accuracy_score(y_true, y_pred),\n",
nkita
nkita
nkita
    "                    'p': precision_score(y_true, y_pred,average='weighted'),\n",
nkita
nkita
nkita
    "                    'r': recall_score(y_true, y_pred,average='weighted'),\n",
nkita
nkita
nkita
    "                    'f1': f1_score(y_true, y_pred,average='weighted')}\n",
nkita
nkita
nkita
    "    \n",
nkita
nkita
nkita
    "    print(ln, metric_dict)\n",
nkita
nkita
nkita
    "    \n",
nkita
nkita
nkita
    "#     score = rouge.get_scores(all_preds, all_refs, avg=True)\n",
nkita
nkita
nkita
    "#     scores[ln] = score['rouge-l']['f']"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 10,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [
nkita
nkita
nkita
    {
nkita
nkita
nkita
     "data": {
nkita
nkita
nkita
      "text/plain": [
nkita
nkita
nkita
       "defaultdict(float, {})"
nkita
nkita
nkita
      ]
nkita
nkita
nkita
     },
nkita
nkita
nkita
     "execution_count": 10,
nkita
nkita
nkita
     "metadata": {},
nkita
nkita
nkita
     "output_type": "execute_result"
nkita
nkita
nkita
    }
nkita
nkita
nkita
   ],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "scores"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 6,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [
nkita
nkita
nkita
    {
nkita
nkita
nkita
     "name": "stderr",
nkita
nkita
nkita
     "output_type": "stream",
nkita
nkita
nkita
     "text": [
nkita
nkita
nkita
      "100%|██████████| 6/6 [00:45<00:00,  7.60s/it]\n"
nkita
nkita
nkita
     ]
nkita
nkita
nkita
    }
nkita
nkita
nkita
   ],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "langScore = {'hi':[],'en':[],'bn':[],'ta':[],'or':[],'pa':[]}\n",
nkita
nkita
nkita
    "for lang in tqdm.tqdm(langScore.keys()):\n",
nkita
nkita
nkita
    "    gptfin = open(f'clfe_scrapes/merged_outputs/{lang}_gpt.csv', mode ='r')\n",
nkita
nkita
nkita
    "    reffin = open(f'/scratch/shivansh.s/intersection/{lang}_test.json', mode='r')\n",
nkita
nkita
nkita
    "    gptData = csv.reader(gptfin)\n",
nkita
nkita
nkita
    "    refData = []\n",
nkita
nkita
nkita
    "    for line in reffin:\n",
nkita
nkita
nkita
    "        refData.append(json.loads(line))\n",
nkita
nkita
nkita
    "    for i,lineData in enumerate(gptData):\n",
nkita
nkita
nkita
    "        if i == 0:\n",
nkita
nkita
nkita
    "            continue\n",
nkita
nkita
nkita
    "        for reflineData in refData:\n",
nkita
nkita
nkita
    "            if lineData[4] == reflineData[\"qid\"]:\n",
nkita
nkita
nkita
    "                refFact = \"\"\n",
nkita
nkita
nkita
    "                for fact in reflineData[\"xalign_facts\"]:\n",
nkita
nkita
nkita
    "                    refFact += fact[0].lower() + \" \" + fact[1].lower() + \" \"\n",
nkita
nkita
nkita
    "                    for punc in string.punctuation:\n",
nkita
nkita
nkita
    "                        refFact = refFact.replace(punc,' ')\n",
nkita
nkita
nkita
    "                gptFact = lineData[2]\n",
nkita
nkita
nkita
    "                gptFact = re.sub(r'<\\|im_end\\|>',r'', gptFact.lower())\n",
nkita
nkita
nkita
    "                for punc in string.punctuation:\n",
nkita
nkita
nkita
    "                    gptFact = gptFact.replace(punc,' ')\n",
nkita
nkita
nkita
    "                gptFact = re.sub(' +', ' ', gptFact.strip())\n",
nkita
nkita
nkita
    "                refFact = re.sub(' +', ' ', refFact.strip())\n",
nkita
nkita
nkita
    "                # score = rouge.get_scores(gptFact, refFact, avg=True)\n",
nkita
nkita
nkita
    "                # langScore[lang].append(score['rouge-l']['f'])\n",
nkita
nkita
nkita
    "\n",
nkita
nkita
nkita
    "                score = bertscore.compute(predictions=[gptFact], references=[refFact], model_type=\"bert-base-multilingual-cased\")\n",
nkita
nkita
nkita
    "                langScore[lang].append(score['f1'][0])    \n",
nkita
nkita
nkita
    "    gptfin.close()\n",
nkita
nkita
nkita
    "    reffin.close()"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 40,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [
nkita
nkita
nkita
    {
nkita
nkita
nkita
     "name": "stdout",
nkita
nkita
nkita
     "output_type": "stream",
nkita
nkita
nkita
     "text": [
nkita
nkita
nkita
      "Rouge-L score for lang: hi is 0.5963631718622646\n",
nkita
nkita
nkita
      "Rouge-L score for lang: en is 0.6563214898029931\n",
nkita
nkita
nkita
      "Rouge-L score for lang: bn is 0.9022970499499996\n",
nkita
nkita
nkita
      "Rouge-L score for lang: ta is 0.7659665247600201\n",
nkita
nkita
nkita
      "Rouge-L score for lang: or is 0.599688542430034\n",
nkita
nkita
nkita
      "Rouge-L score for lang: pa is 0.6006571739311406\n"
nkita
nkita
nkita
     ]
nkita
nkita
nkita
    }
nkita
nkita
nkita
   ],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "for key in langScore.keys():\n",
nkita
nkita
nkita
    "    print(f\"Rouge-L score for lang: {key} is {sum(langScore[key])/len(langScore[key])}\")"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": 7,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [
nkita
nkita
nkita
    {
nkita
nkita
nkita
     "name": "stdout",
nkita
nkita
nkita
     "output_type": "stream",
nkita
nkita
nkita
     "text": [
nkita
nkita
nkita
      "Bert score for lang: hi is 0.832969351051506\n",
nkita
nkita
nkita
      "Bert score for lang: en is 0.868092382395709\n",
nkita
nkita
nkita
      "Bert score for lang: bn is 0.9537793087287688\n",
nkita
nkita
nkita
      "Bert score for lang: ta is 0.9018094785073224\n",
nkita
nkita
nkita
      "Bert score for lang: or is 0.8222764887436917\n",
nkita
nkita
nkita
      "Bert score for lang: pa is 0.84666516322356\n"
nkita
nkita
nkita
     ]
nkita
nkita
nkita
    }
nkita
nkita
nkita
   ],
nkita
nkita
nkita
   "source": [
nkita
nkita
nkita
    "for key in langScore.keys():\n",
nkita
nkita
nkita
    "    print(f\"Bert score for lang: {key} is {sum(langScore[key])/len(langScore[key])}\")"
nkita
nkita
nkita
   ]
nkita
nkita
nkita
  },
nkita
nkita
nkita
  {
nkita
nkita
nkita
   "cell_type": "code",
nkita
nkita
nkita
   "execution_count": null,
nkita
nkita
nkita
   "metadata": {},
nkita
nkita
nkita
   "outputs": [],
nkita
nkita
nkita
   "source": []
nkita
nkita
nkita
  }
nkita
nkita
nkita
 ],
nkita
nkita
nkita
 "metadata": {
nkita
nkita
nkita
  "kernelspec": {
nkita
nkita
nkita
   "display_name": "Python 3 (ipykernel)",
nkita
nkita
nkita
   "language": "python",
nkita
nkita
nkita
   "name": "python3"
nkita
nkita
nkita
  },
nkita
nkita
nkita
  "language_info": {
nkita
nkita
nkita
   "codemirror_mode": {
nkita
nkita
nkita
    "name": "ipython",
nkita
nkita
nkita
    "version": 3
nkita
nkita
nkita
   },
nkita
nkita
nkita
   "file_extension": ".py",
nkita
nkita
nkita
   "mimetype": "text/x-python",
nkita
nkita
nkita
   "name": "python",
nkita
nkita
nkita
   "nbconvert_exporter": "python",
nkita
nkita
nkita
   "pygments_lexer": "ipython3",
nkita
nkita
nkita
   "version": "3.9.7"
nkita
nkita
nkita
  }
nkita
nkita
nkita
 },
nkita
nkita
nkita
 "nbformat": 4,
nkita
nkita
nkita
 "nbformat_minor": 2
nkita
nkita
nkita
}
nkita
nkita
nkita
